{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9ff2b3ac",
   "metadata": {},
   "source": [
    "# Synteettisen datan generointi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5813e65",
   "metadata": {},
   "source": [
    "## Tarvittavat paketit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "66bbf7a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[KeOps] Warning : \n",
      "    The default C++ compiler could not be found on your system.\n",
      "    You need to either define the CXX environment variable or a symlink to the g++ command.\n",
      "    For example if g++-8 is the command you can do\n",
      "      import os\n",
      "      os.environ['CXX'] = 'g++-8'\n",
      "    \n",
      "[KeOps] Warning : Cuda libraries were not detected on the system or could not be loaded ; using cpu only mode\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import sdv\n",
    "import scipy\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.impute import KNNImputer\n",
    "import synthcity\n",
    "\n",
    "from ucimlrepo import fetch_ucirepo \n",
    "\n",
    "\n",
    "\n",
    "import sdmetrics\n",
    "from sdv.metadata import SingleTableMetadata\n",
    "from sdmetrics.reports import utils\n",
    "from sdv.single_table import TVAESynthesizer\n",
    "from sdv.single_table import CTGANSynthesizer\n",
    "from sdv.single_table import GaussianCopulaSynthesizer\n",
    "from sdv.evaluation.single_table import evaluate_quality\n",
    "\n",
    "from DataSynthesizer.DataDescriber import DataDescriber\n",
    "from DataSynthesizer.DataGenerator import DataGenerator\n",
    "from DataSynthesizer.lib.utils import display_bayesian_network\n",
    "\n",
    "from synthcity.plugins import Plugins\n",
    "from synthcity.plugins.core.dataloader import GenericDataLoader\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fea5caf",
   "metadata": {},
   "source": [
    "## Datan valmistelu\n",
    "\n",
    "Haetaan tässä esimerkiksi UCI repositoryn heart disease -data.\n",
    "Tämän tilalle voi vaihtaa jonkun muun taulukkomuotoisen datan ja menetelmät toimivat samalla tavalla.\n",
    "\n",
    "Oman datan saa käyttöön lukemalla sen \"real_data_df\" muuttujaan."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d95b1ef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "  \n",
    "# fetch dataset \n",
    "heart_disease = fetch_ucirepo(id=45) \n",
    "  \n",
    "# data (as pandas dataframes) \n",
    "X = heart_disease.data.features \n",
    "y = heart_disease.data.targets \n",
    "  \n",
    "# metadata \n",
    "# print(heart_disease.metadata) \n",
    "  \n",
    "# variable information \n",
    "# print(heart_disease.variables) \n",
    "\n",
    "# Lisätään ennustettava muuttuja osaksi DataFramea\n",
    "# real_data_df = pd.read_excel(\"omadata.xslx\")\n",
    "real_data_df = pd.concat([pd.DataFrame(X), pd.DataFrame(y)], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb706f1a",
   "metadata": {},
   "source": [
    "Tarkistetaan puuttuvat arvot:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8650ef72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "0",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "ref": "d627af1c-5a43-49f0-af34-d8e017007682",
       "rows": [
        [
         "age",
         "0"
        ],
        [
         "sex",
         "0"
        ],
        [
         "cp",
         "0"
        ],
        [
         "trestbps",
         "0"
        ],
        [
         "chol",
         "0"
        ],
        [
         "fbs",
         "0"
        ],
        [
         "restecg",
         "0"
        ],
        [
         "thalach",
         "0"
        ],
        [
         "exang",
         "0"
        ],
        [
         "oldpeak",
         "0"
        ],
        [
         "slope",
         "0"
        ],
        [
         "ca",
         "4"
        ],
        [
         "thal",
         "2"
        ],
        [
         "num",
         "0"
        ]
       ],
       "shape": {
        "columns": 1,
        "rows": 14
       }
      },
      "text/plain": [
       "age         0\n",
       "sex         0\n",
       "cp          0\n",
       "trestbps    0\n",
       "chol        0\n",
       "fbs         0\n",
       "restecg     0\n",
       "thalach     0\n",
       "exang       0\n",
       "oldpeak     0\n",
       "slope       0\n",
       "ca          4\n",
       "thal        2\n",
       "num         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "real_data_df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77056439",
   "metadata": {},
   "source": [
    "Luodaan viisinkertainen ristiinvalidointi:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1e10ae22",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_folds = []\n",
    "test_folds = []\n",
    "\n",
    "kf = KFold(n_splits=5, random_state=19, shuffle=True)\n",
    "\n",
    "for i, (train_index, test_index) in enumerate(kf.split(real_data_df)):\n",
    "    train_folds.append(real_data_df.iloc[train_index])\n",
    "    test_folds.append(real_data_df.iloc[test_index])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6cf669e",
   "metadata": {},
   "source": [
    "Täydennetään puuttuvat arvot eli imputoidaan. Tässä tapauksessa käytetään k-nearest-neighbor -imputointia:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f7e39114",
   "metadata": {},
   "outputs": [],
   "source": [
    "col_names = real_data_df.columns\n",
    "\n",
    "for i in range(kf.get_n_splits()):\n",
    "    if train_folds[i].isna().sum().sum() > 0:\n",
    "        imputer = KNNImputer(n_neighbors=5)\n",
    "        train_folds[i] = pd.DataFrame(imputer.fit_transform(train_folds[i]), columns=col_names)\n",
    "    if test_folds[i].isna().sum().sum() > 0:\n",
    "        test_folds[i] = pd.DataFrame(imputer.transform(test_folds[i]),columns=col_names)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91c2100c",
   "metadata": {},
   "source": [
    "## Generointi\n",
    "\n",
    "Eri paketit vaativat hieman eri syntaksin.\n",
    "\n",
    "Asetuksia muokkaamalla voi saada parempia/huonompia tuloksia, mutta vakioasetukset tuottavat hyvän peruskäsityksen mallien toimintakyvystä."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fd805019",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_TVAE_data(train_data, n_synth):\n",
    "    if 'ID' in train_data.columns:\n",
    "        train_data.drop('ID', axis=1, inplace=True)\n",
    "    metadata = SingleTableMetadata()\n",
    "    metadata.detect_from_dataframe(train_data)\n",
    "    synth_data_sdv_TVAE = TVAESynthesizer(metadata,\n",
    "                                               compress_dims=(256,128),\n",
    "                                               decompress_dims=(128,256),\n",
    "                                               embedding_dim = 64,\n",
    "                                               enforce_min_max_values = False,\n",
    "                                               epochs=3000)\n",
    "    # synth_data_sdv_TVAE.add_constraints(constraints = constraint_list)\n",
    "\n",
    "    synth_data_sdv_TVAE.fit(train_data)\n",
    "    synth_data_sdv_TVAE = synth_data_sdv_TVAE.sample(n_synth)\n",
    "\n",
    "    return synth_data_sdv_TVAE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6d2508d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_CTGAN_data(train_data, n_synth):\n",
    "    if 'ID' in train_data.columns:\n",
    "        train_data.drop('ID', axis=1, inplace=True)\n",
    "    metadata = SingleTableMetadata()\n",
    "    metadata.detect_from_dataframe(train_data)\n",
    "    synth_data_sdv_CTGAN = CTGANSynthesizer(metadata,\n",
    "                                                enforce_min_max_values = False,\n",
    "                                                epochs=3000)\n",
    "\n",
    "    synth_data_sdv_CTGAN.fit(train_data)\n",
    "    synth_data_sdv_CTGAN = synth_data_sdv_CTGAN.sample(n_synth)\n",
    "\n",
    "    return synth_data_sdv_CTGAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8ceb300b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_gaussiancopula_data(train_data, n_synth):\n",
    "    if 'ID' in train_data.columns:\n",
    "        train_data.drop('ID', axis=1, inplace=True)\n",
    "    metadata = SingleTableMetadata()\n",
    "    metadata.detect_from_dataframe(train_data)\n",
    "    synth_data_sdv_gcopula = GaussianCopulaSynthesizer(metadata,\n",
    "                                                enforce_min_max_values = False)\n",
    "\n",
    "    synth_data_sdv_gcopula.fit(train_data)\n",
    "    synth_data_sdv_gcopula = synth_data_sdv_gcopula.sample(n_synth)\n",
    "\n",
    "    return synth_data_sdv_gcopula"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a86fc973",
   "metadata": {},
   "outputs": [],
   "source": [
    "synth_data_sdv_TVAE_list = []\n",
    "\n",
    "for i in range(kf.get_n_splits()):\n",
    "    synth_data_sdv_TVAE_i = generate_TVAE_data(train_folds[i], n_synth=1000)\n",
    "    synth_data_sdv_TVAE_list.append(synth_data_sdv_TVAE_i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2433b677",
   "metadata": {},
   "outputs": [],
   "source": [
    "synth_data_sdv_CTGAN_list = []\n",
    "\n",
    "for i in range(kf.get_n_splits()):\n",
    "    synth_data_sdv_CTGAN_i = generate_CTGAN_data(train_folds[i], n_synth=1000)\n",
    "    synth_data_sdv_CTGAN_list.append(synth_data_sdv_CTGAN_i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "958df136",
   "metadata": {},
   "outputs": [],
   "source": [
    "synth_data_sdv_gcopula_list = []\n",
    "\n",
    "for i in range(kf.get_n_splits()):\n",
    "    synth_data_sdv_gcopula_i = generate_gaussiancopula_data(train_folds[i], n_synth=1000)\n",
    "    synth_data_sdv_gcopula_list.append(synth_data_sdv_CTGAN_i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d21c8a9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-08-29T15:45:41.715745+0300][4358][CRITICAL] module disabled: /home/joonas/wdl/wdl_workfolder/.venv/lib/python3.10/site-packages/synthcity/plugins/generic/plugin_goggle.py\n",
      "[2025-08-29T15:45:41.717682+0300][4358][CRITICAL] load failed: module 'synthcity.plugins.generic.plugin_great' has no attribute 'plugin'\n",
      "[2025-08-29T15:45:41.719060+0300][4358][CRITICAL] load failed: module 'synthcity.plugins.generic.plugin_great' has no attribute 'plugin'\n",
      "[2025-08-29T15:45:41.720093+0300][4358][CRITICAL] module plugin_great load failed\n",
      " 65%|██████▍   | 649/1000 [00:36<00:19, 18.01it/s]\n",
      "[2025-08-29T15:46:19.710207+0300][4358][CRITICAL] module disabled: /home/joonas/wdl/wdl_workfolder/.venv/lib/python3.10/site-packages/synthcity/plugins/generic/plugin_goggle.py\n",
      "[2025-08-29T15:46:19.711449+0300][4358][CRITICAL] load failed: module 'synthcity.plugins.generic.plugin_great' has no attribute 'plugin'\n",
      "[2025-08-29T15:46:19.712214+0300][4358][CRITICAL] load failed: module 'synthcity.plugins.generic.plugin_great' has no attribute 'plugin'\n",
      "[2025-08-29T15:46:19.712846+0300][4358][CRITICAL] module plugin_great load failed\n",
      " 50%|████▉     | 499/1000 [00:20<00:20, 24.01it/s]\n",
      "[2025-08-29T15:46:42.344013+0300][4358][CRITICAL] module disabled: /home/joonas/wdl/wdl_workfolder/.venv/lib/python3.10/site-packages/synthcity/plugins/generic/plugin_goggle.py\n",
      "[2025-08-29T15:46:42.345175+0300][4358][CRITICAL] load failed: module 'synthcity.plugins.generic.plugin_great' has no attribute 'plugin'\n",
      "[2025-08-29T15:46:42.345999+0300][4358][CRITICAL] load failed: module 'synthcity.plugins.generic.plugin_great' has no attribute 'plugin'\n",
      "[2025-08-29T15:46:42.346629+0300][4358][CRITICAL] module plugin_great load failed\n",
      " 55%|█████▍    | 549/1000 [00:24<00:20, 22.06it/s]\n",
      "[2025-08-29T15:47:09.128558+0300][4358][CRITICAL] module disabled: /home/joonas/wdl/wdl_workfolder/.venv/lib/python3.10/site-packages/synthcity/plugins/generic/plugin_goggle.py\n",
      "[2025-08-29T15:47:09.130003+0300][4358][CRITICAL] load failed: module 'synthcity.plugins.generic.plugin_great' has no attribute 'plugin'\n",
      "[2025-08-29T15:47:09.130874+0300][4358][CRITICAL] load failed: module 'synthcity.plugins.generic.plugin_great' has no attribute 'plugin'\n",
      "[2025-08-29T15:47:09.131754+0300][4358][CRITICAL] module plugin_great load failed\n",
      " 65%|██████▍   | 649/1000 [00:29<00:16, 21.76it/s]\n",
      "[2025-08-29T15:47:40.863990+0300][4358][CRITICAL] module disabled: /home/joonas/wdl/wdl_workfolder/.venv/lib/python3.10/site-packages/synthcity/plugins/generic/plugin_goggle.py\n",
      "[2025-08-29T15:47:40.865435+0300][4358][CRITICAL] load failed: module 'synthcity.plugins.generic.plugin_great' has no attribute 'plugin'\n",
      "[2025-08-29T15:47:40.866193+0300][4358][CRITICAL] load failed: module 'synthcity.plugins.generic.plugin_great' has no attribute 'plugin'\n",
      "[2025-08-29T15:47:40.866903+0300][4358][CRITICAL] module plugin_great load failed\n",
      " 75%|███████▍  | 749/1000 [00:34<00:11, 21.42it/s]\n"
     ]
    }
   ],
   "source": [
    "synth_data_synthcity_nflow_list = []\n",
    "\n",
    "for i in range(kf.get_n_splits()):\n",
    "\n",
    "    synthcity_nflow = Plugins().get(\"nflow\")\n",
    "    synthcity_nflow.fit(train_folds[i], verbose = False)\n",
    "    synth_data_synthcity_nflow_i = synthcity_nflow.generate(count=1000, verbose = False)\n",
    "    synth_data_synthcity_nflow_list.append(synth_data_synthcity_nflow_i.dataframe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "550cfbc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-08-06T14:23:22.795394+0300][2198][CRITICAL] load failed: module 'synthcity.plugins.generic.plugin_great' has no attribute 'plugin'\n",
      "[2025-08-06T14:23:22.796418+0300][2198][CRITICAL] load failed: module 'synthcity.plugins.generic.plugin_great' has no attribute 'plugin'\n",
      "[2025-08-06T14:23:22.797065+0300][2198][CRITICAL] module plugin_great load failed\n",
      "[2025-08-06T14:23:22.797684+0300][2198][CRITICAL] module disabled: /home/pekkamela/wdl/wdl_workfolder/.venv/lib/python3.10/site-packages/synthcity/plugins/generic/plugin_goggle.py\n",
      "Epoch: 100%|██████████| 1000/1000 [00:18<00:00, 54.64it/s, loss=1.17]\n",
      "[2025-08-06T14:24:04.714464+0300][2198][CRITICAL] load failed: module 'synthcity.plugins.generic.plugin_great' has no attribute 'plugin'\n",
      "[2025-08-06T14:24:04.715069+0300][2198][CRITICAL] load failed: module 'synthcity.plugins.generic.plugin_great' has no attribute 'plugin'\n",
      "[2025-08-06T14:24:04.715446+0300][2198][CRITICAL] module plugin_great load failed\n",
      "[2025-08-06T14:24:04.715929+0300][2198][CRITICAL] module disabled: /home/pekkamela/wdl/wdl_workfolder/.venv/lib/python3.10/site-packages/synthcity/plugins/generic/plugin_goggle.py\n",
      "Epoch: 100%|██████████| 1000/1000 [00:14<00:00, 70.62it/s, loss=1.19]\n",
      "[2025-08-06T14:24:51.418716+0300][2198][CRITICAL] load failed: module 'synthcity.plugins.generic.plugin_great' has no attribute 'plugin'\n",
      "[2025-08-06T14:24:51.419260+0300][2198][CRITICAL] load failed: module 'synthcity.plugins.generic.plugin_great' has no attribute 'plugin'\n",
      "[2025-08-06T14:24:51.419647+0300][2198][CRITICAL] module plugin_great load failed\n",
      "[2025-08-06T14:24:51.420022+0300][2198][CRITICAL] module disabled: /home/pekkamela/wdl/wdl_workfolder/.venv/lib/python3.10/site-packages/synthcity/plugins/generic/plugin_goggle.py\n",
      "Epoch: 100%|██████████| 1000/1000 [00:12<00:00, 78.53it/s, loss=1.26]\n",
      "[2025-08-06T14:26:10.899792+0300][2198][CRITICAL] load failed: module 'synthcity.plugins.generic.plugin_great' has no attribute 'plugin'\n",
      "[2025-08-06T14:26:10.900496+0300][2198][CRITICAL] load failed: module 'synthcity.plugins.generic.plugin_great' has no attribute 'plugin'\n",
      "[2025-08-06T14:26:10.900874+0300][2198][CRITICAL] module plugin_great load failed\n",
      "[2025-08-06T14:26:10.901250+0300][2198][CRITICAL] module disabled: /home/pekkamela/wdl/wdl_workfolder/.venv/lib/python3.10/site-packages/synthcity/plugins/generic/plugin_goggle.py\n",
      "Epoch: 100%|██████████| 1000/1000 [00:14<00:00, 69.46it/s, loss=1.17]\n",
      "[2025-08-06T14:27:08.785221+0300][2198][CRITICAL] load failed: module 'synthcity.plugins.generic.plugin_great' has no attribute 'plugin'\n",
      "[2025-08-06T14:27:08.785777+0300][2198][CRITICAL] load failed: module 'synthcity.plugins.generic.plugin_great' has no attribute 'plugin'\n",
      "[2025-08-06T14:27:08.786182+0300][2198][CRITICAL] module plugin_great load failed\n",
      "[2025-08-06T14:27:08.786626+0300][2198][CRITICAL] module disabled: /home/pekkamela/wdl/wdl_workfolder/.venv/lib/python3.10/site-packages/synthcity/plugins/generic/plugin_goggle.py\n",
      "Epoch: 100%|██████████| 1000/1000 [00:14<00:00, 71.21it/s, loss=1.16]\n"
     ]
    }
   ],
   "source": [
    "synth_data_synthcity_diffusion_list = []\n",
    "\n",
    "for i in range(kf.get_n_splits()):\n",
    "    synthcity_diffusion = Plugins().get(\"ddpm\")\n",
    "    synthcity_diffusion.fit(train_folds[i])\n",
    "    synth_data_synthcity_diffusion_i = synthcity_diffusion.generate(count=1000)\n",
    "    synth_data_synthcity_diffusion_list.append(synth_data_synthcity_diffusion_i.dataframe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3c0a6ff5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================ Constructing Bayesian Network (BN) ================\n",
      "Adding ROOT num\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding attribute thalach\n",
      "Adding attribute oldpeak\n",
      "Adding attribute restecg\n",
      "Adding attribute fbs\n",
      "Adding attribute trestbps\n",
      "Adding attribute slope\n",
      "Adding attribute chol\n",
      "Adding attribute thal\n",
      "Adding attribute ca\n",
      "Adding attribute sex\n",
      "Adding attribute exang\n",
      "Adding attribute age\n",
      "Adding attribute cp\n",
      "========================== BN constructed ==========================\n",
      "================ Constructing Bayesian Network (BN) ================\n",
      "Adding ROOT num\n",
      "Adding attribute thalach\n",
      "Adding attribute oldpeak\n",
      "Adding attribute restecg\n",
      "Adding attribute fbs\n",
      "Adding attribute trestbps\n",
      "Adding attribute slope\n",
      "Adding attribute cp\n",
      "Adding attribute thal\n",
      "Adding attribute ca\n",
      "Adding attribute sex\n",
      "Adding attribute exang\n",
      "Adding attribute chol\n",
      "Adding attribute age\n",
      "========================== BN constructed ==========================\n",
      "================ Constructing Bayesian Network (BN) ================\n",
      "Adding ROOT num\n",
      "Adding attribute thalach\n",
      "Adding attribute oldpeak\n",
      "Adding attribute restecg\n",
      "Adding attribute fbs\n",
      "Adding attribute trestbps\n",
      "Adding attribute exang\n",
      "Adding attribute chol\n",
      "Adding attribute thal\n",
      "Adding attribute ca\n",
      "Adding attribute sex\n",
      "Adding attribute slope\n",
      "Adding attribute age\n",
      "Adding attribute cp\n",
      "========================== BN constructed ==========================\n",
      "================ Constructing Bayesian Network (BN) ================\n",
      "Adding ROOT num\n",
      "Adding attribute thalach\n",
      "Adding attribute oldpeak\n",
      "Adding attribute restecg\n",
      "Adding attribute fbs\n",
      "Adding attribute trestbps\n",
      "Adding attribute slope\n",
      "Adding attribute chol\n",
      "Adding attribute thal\n",
      "Adding attribute ca\n",
      "Adding attribute sex\n",
      "Adding attribute exang\n",
      "Adding attribute age\n",
      "Adding attribute cp\n",
      "========================== BN constructed ==========================\n",
      "================ Constructing Bayesian Network (BN) ================\n",
      "Adding ROOT num\n",
      "Adding attribute thalach\n",
      "Adding attribute oldpeak\n",
      "Adding attribute restecg\n",
      "Adding attribute fbs\n",
      "Adding attribute trestbps\n",
      "Adding attribute slope\n",
      "Adding attribute chol\n",
      "Adding attribute thal\n",
      "Adding attribute ca\n",
      "Adding attribute sex\n",
      "Adding attribute exang\n",
      "Adding attribute age\n",
      "Adding attribute cp\n",
      "========================== BN constructed ==========================\n"
     ]
    }
   ],
   "source": [
    "# Specify categorical attributes\n",
    "categorical_attributes = {'sex': True, 'cp': True, 'fbs': True, 'restecg': True, 'exang': True,\n",
    "                          'slope': True,'num': True}\n",
    "\n",
    "# Define privacy settings\n",
    "epsilon = 1\n",
    "degree_of_bayesian_network = 2\n",
    "\n",
    "synth_data_privbayes_list = []\n",
    "\n",
    "for i in range(kf.get_n_splits()):\n",
    "    train_folds[i].to_csv(f'datasynthesizer_files/train_fold_{i}.csv')\n",
    "\n",
    "\n",
    "    # Initialize DataDescriber with category threshold\n",
    "    describer = DataDescriber(category_threshold=5)\n",
    "    # Describe the dataset to create a Bayesian network\n",
    "    describer.describe_dataset_in_correlated_attribute_mode(dataset_file=f'./datasynthesizer_files/train_fold_{i}.csv', \n",
    "                                                        epsilon=epsilon, \n",
    "                                                        k=degree_of_bayesian_network,\n",
    "                                                        attribute_to_is_categorical=categorical_attributes\n",
    "                                                        )\n",
    "    \n",
    "    describer.save_dataset_description_to_file(f'./datasynthesizer_files/description_{i}.json')\n",
    "    generator = DataGenerator()\n",
    "    generator.generate_dataset_in_correlated_attribute_mode(1000, f'./datasynthesizer_files/description_{i}.json')\n",
    "    # Save synthetic data to a CSV file\n",
    "    generator.save_synthetic_data(f'./data/bayes/synteettinen_bayes_data_{i}.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "89220a53",
   "metadata": {},
   "outputs": [],
   "source": [
    "synth_data_privbayes_list = []\n",
    "\n",
    "for i in range(kf.get_n_splits()):\n",
    "    synth_data_privbayes_i = pd.read_csv(f'./datasynthesizer_files/synth_data_{i}.csv', index_col=0)\n",
    "    synth_data_privbayes_list.append(synth_data_privbayes_i)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40f67851",
   "metadata": {},
   "source": [
    "Tallennetaan lopuksi syntynyt data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8d0c20cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, synth_set in enumerate(synth_data_sdv_TVAE_list):\n",
    "    synth_set.to_csv(f\"./data/tvae/synteettinen_tvae_data_{i}.csv\")\n",
    "\n",
    "for i, synth_set in enumerate(synth_data_sdv_CTGAN_list):\n",
    "    synth_set.to_csv(f\"./data/ctgan/synteettinen_ctgan_data_{i}.csv\")\n",
    "\n",
    "for i, synth_set in enumerate(synth_data_sdv_gcopula_list):\n",
    "    synth_set.to_csv(f\"./data/gcopula/synteettinen_gcopula_data_{i}.csv\")\n",
    "\n",
    "for i, synth_set in enumerate(synth_data_synthcity_nflow_list):\n",
    "    synth_set.to_csv(f\"./data/nflow/synteettinen_nflow_data_{i}.csv\")\n",
    "\n",
    "for i, synth_set in enumerate(synth_data_synthcity_diffusion_list):\n",
    "    synth_set.to_csv(f\"./data/diffusion/synteettinen_diffusion_data_{i}.csv\")\n",
    "\n",
    "for i, train_set in enumerate(train_folds):\n",
    "    train_set.to_csv(f\"./data/train/training_data_{i}.csv\")\n",
    "\n",
    "for i, test_set in enumerate(test_folds):\n",
    "    test_set.to_csv(f\"./data/test/testing_data_{i}.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bcb53fd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.10.12)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
